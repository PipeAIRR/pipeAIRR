[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire ViaFoundry pipelines",
    "section": "",
    "text": "Welcome\npipeAIRR is a community resource for adaptive immune receptore repertoire sequencing (AIRR-seq) processing pipelines.\nThe pipelines are implemented with ViaFoundry.\nWe have divided the pipelines into two main sections:"
  },
  {
    "objectID": "index.html#repository-layout",
    "href": "index.html#repository-layout",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire ViaFoundry pipelines",
    "section": "Repository layout",
    "text": "Repository layout\nFor each pipeline you can find a directory containing the ViaFoundry pipeline (main.dn) as well as the configurations and the nextflow script (main.nf)"
  },
  {
    "objectID": "index.html#pre-processing",
    "href": "index.html#pre-processing",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire ViaFoundry pipelines",
    "section": "Pre-processing",
    "text": "Pre-processing\nIn this section you can find pipelines to process the sequencer output files, meaning from ‘raw reads’ into an aligner ready fasta file.\nIn this section you can find pipelines to process the sequencer output files, from ‘raw reads’ into a fasta file ready to be used as an input for an alignment step and other downstream tasks.\nThe pipeplines were built based on the immcantation framework and specifically the pRESTO tool suite.\n\nAvailable pipelines:\n\n\n\nPipeline\nInput data\nSequencing protocol\nUMI\nPublished paper(s)\nGitHub Archive\nZenodo DOI\nViaFoundry pipeline\n\n\n\n\nRP1\nRaw sequences\n2X250\n+\n[11]\npipeAIRR/RP1\n\npipeline/381\n\n\nRP2\nRaw sequences\n2X250\n-\n[4]\npipeAIRR/RP2\n\npipeline/382\n\n\nRP3\nRaw sequences\n5’ RACE\n+\n[3], [1]\npipeAIRR/RP3\n\npipeline/383\n\n\nRP4\nRaw sequences\n2X300\n+\n[2]\npipeAIRR/RP4\n\npipeline/386\n\n\nRP5\nRaw sequences\n5’ RACE\n+\n[9]\npipeAIRR/RP5A, pipeAIRR/RP5B\n, \npipeline/390, pipeline/393\n\n\nRP6\nRaw sequences\nRoche 454\n-\n[5]\npipeAIRR/RP6\n\npipeline/396\n\n\nRP7\nRaw sequences\n2X125 CD4\n-\n[8]\npipeAIRR/RP7\n\n\n\n\npipeline/397"
  },
  {
    "objectID": "index.html#downstream-analysis",
    "href": "index.html#downstream-analysis",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire ViaFoundry pipelines",
    "section": "Downstream analysis",
    "text": "Downstream analysis\nIn this section you can find pipelines to analyze processed reads and infer genotype and haplotype. The pipelines were built based on the Yaari lab framework, which contains tools from: - immcantaton - VDJbase - TIgGER - RAbHIT - PIgLET\n\nAvailable pipelines:\n\n\n\nPipeline\nInput data\nSequencing protocol\nUMI\nPublished paper(s)\nGitHub Archive\nZenodo DOI\nViaFoundry pipeline\n\n\n\n\nPP1\nProcessed sequences\n-\n-\n[10]\npipeAIRR/PP1\n\npipeline/401\n\n\nPP2\nProcessed sequences\n-\n-\n[6]\npipeAIRR/PP2\n\npipeline/402\n\n\nPP3\nProcessed sequences\n-\n-\n[7]\npipeAIRR/PP3\n\npipeline/398\n\n\n\n\nProcessed sequences are the fasta file from the pre-processing step.\n\n\n\nViaFoundry access\nPlease note to access the ViaFoundry pipeline you will need to create an account. You can create an account by contacting the ViaFoundry team support@viascientific.com, for further information please go here"
  },
  {
    "objectID": "index.html#citations",
    "href": "index.html#citations",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire ViaFoundry pipelines",
    "section": "Citations:",
    "text": "Citations:\n[1] Sivan Eliyahu, Oz Sharabi, Shiri Elmedvi, Reut Timor, Ateret Davidovich, Francois Vigneault, Chris Clouser, Ronen Hope, Assy Nimer, Marius Braun, Yaacov Y. Weiss, Pazit Polak, Gur Yaari, and Meital Gal-Tanamy. Antibody repertoire analysis of hepatitis c virus infections identifies immune signatures associated with spontaneous clearance. Frontiers in Immunology, 9:3004, 2018\n[2] Jacob D Galson, Sebastian Schaetzle, Rachael JM Bashford-Rogers, Matthew IJ Ray-313 bould, Aleksandr Kovaltsuk, Gavin J Kilpatrick, Ralph Minter, Donna K Finch, Jorge314 Dias, Louisa K James, et al. Deep sequencing of b cell receptor repertoires from covid-315 19 patients reveals strong convergent immune signatures. Frontiers in immunology,316 11:605170, 2020.\n[3] Moriah Gidoni, Omri Snir, Ayelet Peres, Pazit Polak, Ida Lindeman, Ivana Mikocziova, Vikas Kumar Sarna, Knut EA Lundin, Christopher Clouser, Francois Vigneault, et al. Mosaic deletion patterns of the human antibody heavy chain gene locus shown by bayesian haplotyping. Nature communications, 10(1):1–14, 2019\n[4] Victor Greiff, Ulrike Menzel, Ulrike Haessler, Skylar C Cook, Simon Friedensohn, Tarik A Khan, Mark Pogson, Ina Hellmann, and Sai T Reddy. Quantitative assessment of the robustness of next-generation sequencing of antibody variable gene repertoires from immunized mice. BMC immunology, 15:1–14, 2014.\n[5] Ning Jiang, Jiankui He, Joshua A Weinstein, Lolita Penland, Sanae Sasaki, Xiao-Song He, Cornelia L Dekker, Nai-Ying Zheng, Min Huang, Meghan Sullivan, et al. Lineage structure of the human antibody repertoire in response to influenza vaccination. Science translational medicine, 5(171):171ra19–171ra19, 2013\n[6] Aviv Omer, Or Shemesh, Ayelet Peres, Pazit Polak, Adrian J Shepherd, Corey T Watson, Scott D Boyd, Andrew M Collins, William Lees, and Gur Yaari. Vdjbase: an adaptive immune receptor genotype and haplotype database. Nucleic acids research, 48(D1):D1051–D1056, 2020\n[7] Ayelet Peres, William D Lees, Oscar L Rodriguez, Noah Y Lee, Pazit Polak, Ronen Hope, Meirav Kedmi, Andrew M Collins, Mats Ohlin, Steven H Kleinstein, Corey T Watson, and Gur Yaari. IGHV allele similarity clustering improves genotype inference from adaptive immune receptor repertoire sequencing data. Nucleic Acids Research, page gkad603, 08 2023.\n[8] Teresa Rubio, Maria Chernigovskaya, Susanna Marquez, Cristina Marti, Paula Izquierdo-Altarejos, Amparo Urios, Carmina Montoliu, Vicente Felipo, Ana Conesa, Victor Greiff, et al. A nextflow pipeline for t-cell receptor repertoire reconstruction and analysis from rna sequencing data. ImmunoInformatics, 6:100012, 2022.\n[9] Modi Safra, Zvi Tamari, Pazit Polak, Shachaf Shiber, Moshe Matan, Hani Karameh, Yigal Helviz, Adva Levy-Barda, Vered Yahalom, Avi Peretz, et al. Altered somatic hypermutation patterns in covid-19 patients classifies disease severity. Frontiers in Immunology, 14:1031914, 2023.13\n[10] Modi Safra, Lael Werner, Ayelet Peres, Pazit Polak, Naomi Salamon, Michael Schvimer, Batia Weiss, Iris Barshack, Dror S Shouval, and Gur Yaari. A somatic hypermutation based machine learning model stratifies individuals with crohn’s disease and controls. Genome Research, 33(1):71–79, 2023\n[11] Joel NH Stern, Gur Yaari, Jason A Vander Heiden, George Church, William F Donahue, Rogier Q Hintzen, Anita J Huttner, Jon D Laman, Rashed M Nagra, Alyssa Nylander, et al. B cells populating the multiple sclerosis brain mature in the draining cervical lymph nodes. Science translational medicine, 6(248):248ra107–248ra107, 2014"
  },
  {
    "objectID": "frequency_question.html",
    "href": "frequency_question.html",
    "title": "1  Frequently Asked Questions",
    "section": "",
    "text": "How to run a pipeline in viafoundry?\nHow to build a process in viafoundry?\nHow to build a module in viafoundry?\nHow to build a pipeline in viafoundry?\nWhat is the meaning of “Pipeline Header Script?\nIs it possible to run a pipeline with two different containers?\nHow to set up pipeline default parameters?\nHow to set up pipeline default run environment?"
  },
  {
    "objectID": "Run_pipeline_nf.html",
    "href": "Run_pipeline_nf.html",
    "title": "2  Running Nextflow Pipelines from GitHub Repositories",
    "section": "",
    "text": "Follow these steps to run Nextflow pipelines hosted on GitHub:\nPrerequisites\n\nNextflow: Ensure Nextflow is installed on your system. Follow the official installation guide.\nDocker: Many Nextflow pipelines require Docker. Install Docker by following the official guide.\n\n1. Prepare Your Environment\nEnsure your Nextflow and Docker installations are up to date and correctly configured.\n2. Define the Pipeline Repository\nDefine the GitHub repository and its version containing the Nextflow pipeline you wish to run:\nnextflowScript = &lt;Repository_URL&gt;\nnextflowScriptVersion = &lt;Repository_Version&gt;'\n# Replace &lt;Repository_URL&gt; and &lt;Repository_Version&gt; with the appropriate values for the pipeline you're using.\n3. Configure Pipeline Parameters\nIdentify the input parameters required by the pipeline. These may include paths to input files, output directories, and other configuration options. Set these parameters using variables:\ninput=\"path/to/input\"\noutputPath=\"path/to/output\"\n# Add more variables as needed\n4. Run the Pipeline\nConstruct and execute the Nextflow command with your parameters:\nnextflow run  ${nextflowScript} -r ${nextflowScriptVersion} -with-docker --input '${input}' --output '${outputPath}' # Add other parameters as needed\n#Replace --input and --output with the appropriate parameter names for your pipeline.\n5. Monitor Execution and Check Outputs\nNextflow will print progress logs to the console. Monitor these logs to ensure the pipeline is executing as expected. Outputs will be saved to the specified output directory.\nBy following these steps, you can run any Nextflow pipeline hosted on GitHub. Customize the input parameters and execution options based on the specific requirements of the pipeline you’re using."
  },
  {
    "objectID": "script_for_params.html",
    "href": "script_for_params.html",
    "title": "3  An easy way to set pipeline default parameters",
    "section": "",
    "text": "Follow these steps to set default parameters for the pipeline:\n1. Download the “params_viafoundry.R” script from GitHub\nhttps://github.com/pipeAIRR/params_viafoundry\n2. Create a csv file of pipeline parameters\nCreate a csv file that contain a table that each row is a parameter you want to defined.\nThe table columns: - module - the module name - process - the process name - parameter - the parameter name - value - the parameter value\n3. Run the script from the command line\nRscript params_dolphinnext.R csv_file.csv\n4. Copy output \nCopy the text from the file.txt that created to the “Pipeline Header Script” in the “Advanced” tab of the pipeline."
  },
  {
    "objectID": "tweak_param.html",
    "href": "tweak_param.html",
    "title": "4  How to tweaked parameters for an existing pipeline?",
    "section": "",
    "text": "There are two option to tweaked parameters for an existing pipeline.\n1. To change the param of an existing pipeline in viafoundry:\n\nGo to the “Advanced” tab of the pipeline.\nFind and change the desired parameter in the “Pipeline Header Script”.\n\n\n\nSave the change.\n\n2. To change the param of an existing nextflow pipeline:\n\nGo to the nextflow.config file.\nFind and change the desired parameter in the file.\nSave the change."
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "5  Recommended documentation format",
    "section": "",
    "text": "Follow these recommends format for documenting pipelines with clarity and efficiency.\nA pipeline for {short summary} that was produced in the same fashion as those in {paper}.\n\n**Library preparation and sequencing method:**\n\n  {explanation about the sequence}\n\n\n**Input files:**\n\n1. {file 1}\n2. {file 2}\n\n   .\n  \n   .\n  \n   .\n\n**To test the pipeline:**\n\n{optional test mathod}\n\n\n**Output files:**\n\n1. {file 1}\n2. {file 2}\n\n   .\n  \n   .\n  \n   .\n\n**Pipeline container:**\n\n* Docker: {docker image}\n\n\n**Sequence processing steps:**\n\n1. {step 1}\n2. {step 2}\n   .\n  \n   .\n  \n   .\n\n**File used:**\n\n* {file 1}\n* {file 2}\n  .\n  \n  .\n  \n  ."
  },
  {
    "objectID": "zenodo.html",
    "href": "zenodo.html",
    "title": "6  Archive GitHub Repository in Zenodo",
    "section": "",
    "text": "Follow these steps to archive your GitHub repository in Zenodo:\n1. Create a Release in GitHub:\n\nGo to your GitHub repository.\nClick on the “Releases” tab.\nDraft a new release, providing necessary information.\nPublish the release.\n\n2. Create a Zenodo Account:\n\nIf not already done, create an account on Zenodo.\n\n3. Connect GitHub and Zenodo:\n\nIn Zenodo, navigate to the “GitHub Sync” tab.\nAuthorize Zenodo to access your GitHub repositories.\n\n4. Deposit from GitHub:\n\nIn Zenodo, go to the “Upload” page.\nSelect “GitHub” as the upload method.\nChoose the repository and release.\nFill in metadata details.\nStart the upload.\n\n5. Check the Archival Process:\n\nAfter completion, Zenodo will provide a DOI for your repository.\nFind the archived repository on your Zenodo profile.\n\n6. Citation:\n\nUse the DOI to cite your GitHub repository in publications.\n\nNow your GitHub repository is archived in Zenodo and can be referenced with a DOI."
  }
]