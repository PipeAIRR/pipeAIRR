[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "",
    "text": "Welcome\npipeAIRR is a community resource for adaptive immune receptor repertoire sequencing (AIRR-seq) processing pipelines.\nThe pipelines are implemented with DolphinNext.\nWe have divided the pipelines into two main sections: 1. Pre-processing 2. Downstream analysis"
  },
  {
    "objectID": "index.html#repository-layout",
    "href": "index.html#repository-layout",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "Repository layout",
    "text": "Repository layout\nIn each section directory you can find each of the pipelines directories containing the DolphinNext pipeline (XX.dn) as well as the configurations and the Nextflow script (XX.nf)"
  },
  {
    "objectID": "index.html#frequent-questions-and-guides",
    "href": "index.html#frequent-questions-and-guides",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "Frequent questions and guides",
    "text": "Frequent questions and guides\nWe created a small website with frequent questions, guides, and link to relevant information from DolphinNext.\nPlease visit the site to see our guides."
  },
  {
    "objectID": "index.html#pre-processing-from-raw-fastq-files-to-air-seq-annotation-ready",
    "href": "index.html#pre-processing-from-raw-fastq-files-to-air-seq-annotation-ready",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "Pre-processing: From raw FASTQ files to AIR-seq annotation ready",
    "text": "Pre-processing: From raw FASTQ files to AIR-seq annotation ready\nIn this section you can find pipelines to process the sequencer output files, meaning from ‘raw reads’ into an aligner ready fasta file.\nThe pipeplines were build based on the immcantation framework and spesificly the pRESTO tool suite.\n\nAvailable pipelines:\n\n\n\nPipeline\nInput data\nSequencing protocol\nUMI\nPublished paper(s)\nGitHub Archive\n\n\n\n\nRP1\nRaw sequences\n2X250\n+\n[11]\npipeAIRR/RP1\n\n\nRP2\nRaw sequences\n2X250\n-\n[4]\npipeAIRR/RP2\n\n\nRP3\nRaw sequences\n5’ RACE\n+\n[3], [1]\npipeAIRR/RP3\n\n\nRP4\nRaw sequences\n2X300\n+\n[2]\npipeAIRR/RP4\n\n\nRP5\nRaw sequences\n5’ RACE\n+\n[9]\npipeAIRR/RP5A,pipeAIRR/RP5B\n\n\nRP6\nRaw sequences\nRoche 454\n-\n[5]\npipeAIRR/RP6\n\n\nRP7\nRaw sequences\n2X125 CD4\n-\n[8]\npipeAIRR/RP7"
  },
  {
    "objectID": "index.html#annotating-analysis-pipelines-airr-seq-analyses-workflows",
    "href": "index.html#annotating-analysis-pipelines-airr-seq-analyses-workflows",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "Annotating analysis pipelines: AIRR-seq analyses workflows",
    "text": "Annotating analysis pipelines: AIRR-seq analyses workflows\nIn this section you can find pipelines to analyze processed reads and infer genotype and haplotype. The pipelines were build based on the Yaari lab framework, that contains tools from: - immcantaton - VDJbase - TIgGER - RAbHIT - PIgLET\n\nAvailable pipelines:\n\n\n\nPipeline\nInput data\nSequencing protocol\nUMI\nPublished paper(s)\nGitHub Archive\n\n\n\n\nPP1\nProcessed sequences\n-\n-\n[10]\npipeAIRR/PP1\n\n\nPP2\nProcessed sequences\n-\n-\n[6]\npipeAIRR/PP2\n\n\nPP3\nProcessed sequences\n-\n-\n[7]\npipeAIRR/PP3"
  },
  {
    "objectID": "index.html#citations",
    "href": "index.html#citations",
    "title": "pipeAIRR - Github repository for Adaptive immune receptor repertoire pipelines",
    "section": "Citations:",
    "text": "Citations:\n[1] Sivan Eliyahu, Oz Sharabi, Shiri Elmedvi, Reut Timor, Ateret Davidovich, Francois Vigneault, Chris Clouser, Ronen Hope, Assy Nimer, Marius Braun, Yaacov Y. Weiss, Pazit Polak, Gur Yaari, and Meital Gal-Tanamy. Antibody repertoire analysis of hepatitis c virus infections identifies immune signatures associated with spontaneous clearance. Frontiers in Immunology, 9:3004, 2018\n[2] Jacob D Galson, Sebastian Schaetzle, Rachael JM Bashford-Rogers, Matthew IJ Ray-313 bould, Aleksandr Kovaltsuk, Gavin J Kilpatrick, Ralph Minter, Donna K Finch, Jorge314 Dias, Louisa K James, et al. Deep sequencing of b cell receptor repertoires from covid-315 19 patients reveals strong convergent immune signatures. Frontiers in immunology,316 11:605170, 2020.\n[3] Moriah Gidoni, Omri Snir, Ayelet Peres, Pazit Polak, Ida Lindeman, Ivana Mikocziova, Vikas Kumar Sarna, Knut EA Lundin, Christopher Clouser, Francois Vigneault, et al. Mosaic deletion patterns of the human antibody heavy chain gene locus shown by bayesian haplotyping. Nature communications, 10(1):1–14, 2019\n[4] Victor Greiff, Ulrike Menzel, Ulrike Haessler, Skylar C Cook, Simon Friedensohn, Tarik A Khan, Mark Pogson, Ina Hellmann, and Sai T Reddy. Quantitative assessment of the robustness of next-generation sequencing of antibody variable gene repertoires from immunized mice. BMC immunology, 15:1–14, 2014.\n[5] Ning Jiang, Jiankui He, Joshua A Weinstein, Lolita Penland, Sanae Sasaki, Xiao-Song He, Cornelia L Dekker, Nai-Ying Zheng, Min Huang, Meghan Sullivan, et al. Lineage structure of the human antibody repertoire in response to influenza vaccination. Science translational medicine, 5(171):171ra19–171ra19, 2013\n[6] Aviv Omer, Or Shemesh, Ayelet Peres, Pazit Polak, Adrian J Shepherd, Corey T Watson, Scott D Boyd, Andrew M Collins, William Lees, and Gur Yaari. Vdjbase: an adaptive immune receptor genotype and haplotype database. Nucleic acids research, 48(D1):D1051–D1056, 2020\n[7] Ayelet Peres, William D Lees, Oscar L Rodriguez, Noah Y Lee, Pazit Polak, Ronen Hope, Meirav Kedmi, Andrew M Collins, Mats Ohlin, Steven H Kleinstein, Corey T Watson, and Gur Yaari. IGHV allele similarity clustering improves genotype inference from adaptive immune receptor repertoire sequencing data. Nucleic Acids Research, page gkad603, 08 2023.\n[8] Teresa Rubio, Maria Chernigovskaya, Susanna Marquez, Cristina Marti, Paula Izquierdo-Altarejos, Amparo Urios, Carmina Montoliu, Vicente Felipo, Ana Conesa, Victor Greiff, et al. A nextflow pipeline for t-cell receptor repertoire reconstruction and analysis from rna sequencing data. ImmunoInformatics, 6:100012, 2022.\n[9] Modi Safra, Zvi Tamari, Pazit Polak, Shachaf Shiber, Moshe Matan, Hani Karameh, Yigal Helviz, Adva Levy-Barda, Vered Yahalom, Avi Peretz, et al. Altered somatic hypermutation patterns in covid-19 patients classifies disease severity. Frontiers in Immunology, 14:1031914, 2023.13\n[10] Modi Safra, Lael Werner, Ayelet Peres, Pazit Polak, Naomi Salamon, Michael Schvimer, Batia Weiss, Iris Barshack, Dror S Shouval, and Gur Yaari. A somatic hypermutation based machine learning model stratifies individuals with crohn’s disease and controls. Genome Research, 33(1):71–79, 2023\n[11] Joel NH Stern, Gur Yaari, Jason A Vander Heiden, George Church, William F Donahue, Rogier Q Hintzen, Anita J Huttner, Jon D Laman, Rashed M Nagra, Alyssa Nylander, et al. B cells populating the multiple sclerosis brain mature in the draining cervical lymph nodes. Science translational medicine, 6(248):248ra107–248ra107, 2014"
  },
  {
    "objectID": "local_dolphinnext.html",
    "href": "local_dolphinnext.html",
    "title": "1  How to set a local dolphinnext instant?",
    "section": "",
    "text": "1. Pull DolphinNext-studio docker image:\ndocker pull ummsbiocore/dolphinnext-studio\n\n\n\n\n2. Start the container:\n\n\n3. Shifting the database outside the container ensures persistent changes across container restarts. Select a directory on your machine to mount, like ~/export, for this purpose.\nmkdir ~/export\n4. docker run –privileged -m 10G -p 8080:80 -v ~/export:/export -ti ummsbiocore/dolphinnext-studio /bin/bash\n5. After you start the container, you need to start the mysql and apache server using the command: startup\n6. Navigate to http://localhost:8080/dolphinnext/\n7. For more information go to https://github.com/dolphinnext/dolphinnext-tutorial"
  },
  {
    "objectID": "import_pipeline.html",
    "href": "import_pipeline.html",
    "title": "2  How to import a pipeline to dolphinNext?",
    "section": "",
    "text": "1. Launch your DolphinNext docker\nOUTDIR=${replace_with_your_directory}\ndocker run --privileged -m 10G -p 8080:80 -v $OUTDIR:/export -ti ummsbiocore/dolphinnext-studio /bin/bash\n# inside the docker\nstartup\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Click on the “Pipelines” tab\n\n4. Click on the “new pipeline” button\n\n5. Click on “Input Pipeline”\n\n6. Click on the “Select File” button\n\n7. Choose the “main.dn” file\n\n8. Click on the “Next” button\n\n9. Click on the “Import” button\n\n10. Click on the “Complete” button"
  },
  {
    "objectID": "run_pipeline.html",
    "href": "run_pipeline.html",
    "title": "3  How to run a pipeline in dolphinNext?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Choose your pipeline\n\n4. Click on “Run” button\n\n5. Click on “Create New Run” option\n\n6. Choose the Project or create a new one\n\n7. Click on “Select Project” button\n\n8. Enter run name and click on “Save run”\n\n9. Choose run enviroment\n\n10. Enter work directory\n\n11. Enter the files and values the pipeline need\n\n12. Click on “Run” button\n\n13. Choose “Start” option\n\n14. For more information how to run pipeline go to \nhttps://dolphinnext.readthedocs.io/en/latest/dolphinNext/project.html\n15. For information about the run page go to  https://dolphinnext.readthedocs.io/en/latest/dolphinNext/run.html"
  },
  {
    "objectID": "tweak_and_run.html",
    "href": "tweak_and_run.html",
    "title": "4  How to create a run with tweaked parametrs in DolphinNext?",
    "section": "",
    "text": "1. Launch your DolphinNext docker\nOUTDIR=${replace_with_your_directory}\ndocker run --privileged -m 10G -p 8080:80 -v $OUTDIR:/export -ti ummsbiocore/dolphinnext-studio /bin/bash\n# inside the docker\nstartup\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Choose your pipeline\n\n4. Click on the “run” button\n\n5. Choose “Create New Run”\n\n6. Select a project or create a new one\n\n7. Enter run name and click on the “Save run” button\n\n8. Find the module of the parameter you want to change\n\n9. Change the “no” to “yes” and click on the settings button \n\n10. Enter the new parametrs for this module. The parametrs that appear are the default in the module (not in the pipeline)\n\n11. Click on the “Ok” button\n\n12. Run the pipeline with the tweaked parameters"
  },
  {
    "objectID": "hardcode_tweak_param.html",
    "href": "hardcode_tweak_param.html",
    "title": "5  How to hardcode tweak parameters for an imported pipeline?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Choose your pipeline\n\n4. Click on “Advanced” tab\n\n5. See the default parameter in the “Pipeline Header Script”\n\n6. Find the parameter you want to change and set him to the new value\n\n7. Save the change\n\n8. Click on “Overwrite” or “Save as New Revision” button\n\n9. Export the Tweak pipeline"
  },
  {
    "objectID": "build_process.html",
    "href": "build_process.html",
    "title": "6  How to build a process in dolphinNext?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Click on “Pipelines” tab\n\n4. Click on “New Process” button\n\n5. Enter input output params\n\n6. Write the script\n\n7. For more information go to\nhttps://dolphinnext.readthedocs.io/en/latest/dolphinNext/process.html"
  },
  {
    "objectID": "build_module.html",
    "href": "build_module.html",
    "title": "7  How to build a module in dolphinNext?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Click on “Pipelines” tab\n\n4. Click on “New Pipeline” button\n\n5. Add pipeline description, workflow and advanced \n\n6. For more information go to \nhttps://dolphinnext.readthedocs.io/en/latest/dolphinNext/pipeline.html"
  },
  {
    "objectID": "build_pipeline.html",
    "href": "build_pipeline.html",
    "title": "8  How to build a pipeline in dolphinNext?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Click on “Pipelines” tab\n\n4. Click on “New Pipeline” button\n\n5. Add pipeline description, workflow and advanced \n\n6. For more information go to \nhttps://dolphinnext.readthedocs.io/en/latest/dolphinNext/pipeline.html"
  },
  {
    "objectID": "export_a_pipeline.html",
    "href": "export_a_pipeline.html",
    "title": "9  How to export a pipeline from dolphinNext?",
    "section": "",
    "text": "1. Launch your dolphinnext docker\n2. Navigate to http://localhost:8080/dolphinnext/\n3. Click on “Pipelines” tab\n\n4. Choose your pipeline\n\n5. Click on “Download Pipeline”"
  },
  {
    "objectID": "default_param.html",
    "href": "default_param.html",
    "title": "10  How to set pipeline default parameters and run environment?",
    "section": "",
    "text": "1. Choose your pipeline\n\n2. Click on “Advanced” tab\n\n3. Go to “Pipeline Header Script” section \n\n4. First add for each process an option to change the parameters. To do that, the first step must be access the params variable, then the module name and finally the process name.\n\n5. Setting default parameters\nTo set the parameters of a process, the first step must be access the params variable, then the module name, the process name, and finally the parameter name.\n\n6. Setting run environment\nDifferent run environments can be set for various machines, with ”if and else” statement. The $HOSTNAME variable holds the machine name, where ’default’ is usually the local machine. To control the Docker or Singularity image, the $DOCKER_IMAGE variable or the $SINGULARITY_IMAGE variable needs to be allocated. Moreover, the Docker or Singularity properties can be defined also. Additionally, the configuration of machine properties specifically for remote machines also can be defined.\n\n7. Save the change\n\n8. Click on “Overwrite” to save"
  },
  {
    "objectID": "script_for_params.html",
    "href": "script_for_params.html",
    "title": "11  An easy way to set pipeline default parameters",
    "section": "",
    "text": "1. Download the “params_dolphinnext.R” script from GitHub\nhttps://github.com/PipeAIRR/params_dolphinnext\n2. Create a csv file of pipeline parameters\nCreate a csv file that contain a table that each row is a parameter you want to defined.\nThe table columns: - module - the module name - process - the process name - parameter - the parameter name - value - the parameter value\n3. Run the script from the command line\nRscript params_dolphinnext.R csv_file.csv\n4. Copy output \nCopy the text from the file.txt that created to the “Pipeline Header Script” in the “Advanced” tab of the pipeline."
  },
  {
    "objectID": "two_dockers.html",
    "href": "two_dockers.html",
    "title": "12  Is it possible to run a pipeline with 2 dockers?",
    "section": "",
    "text": "1. Choose your pipeline\n\n2. show “Workflow”\n\n3. This process need to run on a “milaboratory/mixcr:latest” docker image\n\n4. This process need to run on a “ssnnm/mhecd4tcr:0.1.0” docker image\n\n5. Click on “Advanced” tab\n\n6. How to define the containers:\nThe docker images needed to defined on the the nextflow.config file as a new process contains “container=” the main docker image and for each process that needed to run with different docker write “WithName:” the process name and in {} “container=” the image docker for this step."
  }
]